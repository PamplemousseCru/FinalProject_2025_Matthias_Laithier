{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5235964d",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafb8a88",
   "metadata": {},
   "source": [
    "The goal here is to test the Mean Squared Error of our model on the test data, and compare it to a basline.\n",
    "\n",
    "This step is to make sure our model actually learned from the training before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca20fe9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50849516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 10:37:20.065104: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-17 10:37:20.122736: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747471040.133835 1719589 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747471040.138944 1719589 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747471040.167700 1719589 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747471040.167707 1719589 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747471040.167708 1719589 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747471040.167709 1719589 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-17 10:37:20.173304: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d26d62",
   "metadata": {},
   "source": [
    "## Loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9f69f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = \"./exports/test_data/\"\n",
    "test_dataset = pd.read_parquet(export_dir + \"test_dataset.pq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5ee5e",
   "metadata": {},
   "source": [
    "## Creating the tensorflow test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0725e40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747471044.066499 1719589 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13687 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "user_columns = [f\"avg_feat_{i}\" for i in range(31)] + [f\"avg_category_{i}\" for i in range(1, 40)]\n",
    "video_columns = [\"video_duration\", \"trend_score\"] + [f\"feat_{i}\" for i in range(31)] + [f\"category_{i}\" for i in range(1, 40)]\n",
    "label_column = [\"watch_ratio\"]\n",
    "\n",
    "X_user_test = test_dataset[user_columns].to_numpy()\n",
    "X_video_test = test_dataset[video_columns].to_numpy()\n",
    "y_test = test_dataset[label_column].values\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((X_user_test, X_video_test),))\n",
    "BATCH_SIZE = 2048\n",
    "dataset = dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd6fd1c",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dc6ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = \"./exports/trained_model/\"\n",
    "model = tf.keras.models.load_model(export_dir + \"model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e745bfb3",
   "metadata": {},
   "source": [
    "## Comparing to a baseline on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fde7bc",
   "metadata": {},
   "source": [
    "In order to know if our model learned something, we have to compare it to a baseline.\n",
    "\n",
    "The baseline we chose is one that would just output the average watch ratio of all the videos accross the entire dataset, no matter the features. We also chose the mae (Mean Absolute Error) to compare the base to our model.\n",
    "\n",
    "The goal is for our trained neural network to be better than this baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7301044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAE: 0.4207\n",
      "Trained model mean absolute error: 0.3485\n"
     ]
    }
   ],
   "source": [
    "baseline_predictions = np.full_like(y_test, np.mean(y_test), dtype=np.float32)\n",
    "baseline_mae = np.mean(np.abs(baseline_predictions.flatten() - y_test.flatten()))\n",
    "print(f\"Baseline MAE: {baseline_mae:.4f}\")\n",
    "\n",
    "model_predictions = model.predict(dataset, verbose=False)\n",
    "model_mae = np.mean(np.abs(model_predictions.flatten() - y_test.flatten()))\n",
    "print(f\"Trained model mean absolute error: {model_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326c6904",
   "metadata": {},
   "source": [
    "We can see that our model is better than our baseline by a significant margin, which is promising."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
